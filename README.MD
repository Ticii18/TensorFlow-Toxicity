#  Detector de Toxicidad con TensorFlow.js

Este proyecto es una pequeña aplicación web que permite detectar si una palabra o frase contiene contenido tóxico, utilizando el modelo preentrenado de TensorFlow.js llamado "toxicity".

---

## 📋 ¿Qué hace este proyecto?

- Permite ingresar una palabra o frase en una caja de texto.
- Usa el modelo `toxicity` de TensorFlow.js para analizar el texto.
- Muestra en pantalla **todo el resultado en formato JSON**, indicando si se detectó toxicidad en distintas categorías (como insultos,lenguaje obsceno, etc).

---

## 🚀 ¿Cómo usarlo?

1. **Cloná el repositorio o descargá los archivos**

Si estás usando Git:

```
git clone https://github.com/Ticii18/TensorFlow-Toxicity.git
```

1. **Abre el archivo `index.html` en tu navegador**

Solo hacé doble clic sobre `index.html` o abrilo desde tu navegador preferido.

3. **Usá la app**

- Espera que se muestre un mensaje donde indica que el modulo se ha cargado.
- Escribe una palabra o frase.
- Presioná el botón **"Verificar"**.
- Vas a ver el resultado completo del análisis en formato JSON.

---

## 🧠 ¿Qué tecnologías se usa?

- [TensorFlow.js](https://www.tensorflow.org/js): para cargar y usar el modelo de toxicidad directamente en el navegador.
- HTML y JavaScript puro: sin frameworks.



---

Autor: Vera Ticiano

---
