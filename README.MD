#  Detector de Toxicidad con TensorFlow.js

Este proyecto es una peque침a aplicaci칩n web que permite detectar si una palabra o frase contiene contenido t칩xico, utilizando el modelo preentrenado de TensorFlow.js llamado "toxicity".

---

## 游늶 쯈u칠 hace este proyecto?

- Permite ingresar una palabra o frase en una caja de texto.
- Usa el modelo `toxicity` de TensorFlow.js para analizar el texto.
- Muestra en pantalla **todo el resultado en formato JSON**, indicando si se detect칩 toxicidad en distintas categor칤as (como insultos,lenguaje obsceno, etc).

---

## 游 쮺칩mo usarlo?

1. **Clon치 el repositorio o descarg치 los archivos**

Si est치s usando Git:

```
git clone https://github.com/Ticii18/TensorFlow-Toxicity.git
```

1. **Abre el archivo `index.html` en tu navegador**

Solo hac칠 doble clic sobre `index.html` o abrilo desde tu navegador preferido.

3. **Us치 la app**

- Espera que se muestre un mensaje donde indica que el modulo se ha cargado.
- Escribe una palabra o frase.
- Presion치 el bot칩n **"Verificar"**.
- Vas a ver el resultado completo del an치lisis en formato JSON.

---

## 游 쯈u칠 tecnolog칤as se usa?

- [TensorFlow.js](https://www.tensorflow.org/js): para cargar y usar el modelo de toxicidad directamente en el navegador.
- HTML y JavaScript puro: sin frameworks.



---

Autor: Vera Ticiano

---
